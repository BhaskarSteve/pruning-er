base_model: Qwen/Qwen2.5-0.5B-Instruct
trust_remote_code: true 

datasets:
  - path: data/s1k-gemini_chatml.jsonl        # from the prep script you ran
    type: chat_template
    chat_template: chatml              # renders <|im_start|>{role} ... <|im_end|>
    field_messages: messages
    # Train only on these roles (so the question/user text has no loss)
    roles_to_train: ["think", "answer"]

special_tokens:
  eos_token: "<|im_end|>"

# ===== Training schedule =====
num_train_epochs: 3

micro_batch_size: 1            # per-GPU micro batch (safe on a single A40)
gradient_accumulation_steps: 16
# DO NOT set 'batch_size' when 'gradient_accumulation_steps' is present

optimizer: adamw_torch
learning_rate: 1.0e-5
weight_decay: 1.0e-4
adam_beta1: 0.9
adam_beta2: 0.95

lr_scheduler_type: cosine
warmup_ratio: 0.05

bf16: true
tf32: true
gradient_checkpointing: true   # big VRAM saver

# ===== Context length =====
# Start with 8k on an A40; bump to 16k if it fits.
sequence_len: 8192
sample_packing: false

# ===== Logging / saving =====
save_strategy: "epoch"
eval_strategy: "no"      # not "none"
logging_steps: 10
seed: 42
output_dir: outputs/qwen25-3b-s1k-sft
